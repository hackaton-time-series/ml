{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "00879f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def downsample_df(df: pd.DataFrame, n_minutes: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downsample a DataFrame based on time index by averaging over n-minute intervals.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Date' as the index.\n",
    "        n_minutes (int, optional): Number of minutes to resample. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Downsampled DataFrame with 'Date' as index.\n",
    "    \"\"\"\n",
    "    \n",
    "    if df.index.name != 'Date':\n",
    "        raise ValueError(\"The DataFrame index should be named 'Date'.\")\n",
    "\n",
    "    df_downsampled = df.resample(f'{n_minutes}min').mean()\n",
    "\n",
    "    return df_downsampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6484ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_clean.csv', parse_dates=['Date'])\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "044433e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def upsample_dataframe(df: pd.DataFrame, output_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Upsample a DataFrame from its current time frequency to 1-minute frequency with linear interpolation.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with a datetime index.\n",
    "        output_file (str): Path where the upsampled CSV will be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Upsampled DataFrame with 'Date' as index.\n",
    "    \"\"\"\n",
    "    full_index = pd.date_range(start=df.index.min(),\n",
    "                               end=df.index.max(),\n",
    "                               freq='min')\n",
    "\n",
    "    df_upsampled = df.reindex(full_index)\n",
    "    df_upsampled = df_upsampled.interpolate(method='linear')\n",
    "\n",
    "    df_upsampled_reset = df_upsampled.reset_index().rename(columns={'index': 'Date'})\n",
    "    df_upsampled_reset.to_csv(output_file, index=False)\n",
    "\n",
    "    df_upsampled_final = df_upsampled_reset.set_index('Date')\n",
    "\n",
    "    # print(df_upsampled_final.head(10))\n",
    "\n",
    "    return df_upsampled_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8ae9a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Series1   Series2   Series3   Series4   Series5  \\\n",
      "Date                                                                    \n",
      "2012-01-01 00:00:00  0.403768 -1.354055  2.013771  1.059627 -1.803735   \n",
      "2012-01-01 00:01:00  0.378759 -1.401326  2.016198  1.063940 -1.489319   \n",
      "2012-01-01 00:02:00  0.353751 -1.448597  2.018624  1.068252 -1.174903   \n",
      "2012-01-01 00:03:00  0.328742 -1.495867  2.021051  1.072565 -0.860487   \n",
      "2012-01-01 00:04:00  0.303734 -1.543138  2.023478  1.076878 -0.546071   \n",
      "2012-01-01 00:05:00  0.278726 -1.590409  2.025904  1.081190 -0.231655   \n",
      "2012-01-01 00:06:00  0.242043 -1.599944  1.979857  1.047665 -0.023642   \n",
      "2012-01-01 00:07:00  0.205360 -1.609478  1.933810  1.014140  0.184371   \n",
      "2012-01-01 00:08:00  0.168677 -1.619013  1.887762  0.980615  0.392384   \n",
      "2012-01-01 00:09:00  0.131995 -1.628547  1.841715  0.947089  0.600397   \n",
      "\n",
      "                      Series6  \n",
      "Date                           \n",
      "2012-01-01 00:00:00 -0.877699  \n",
      "2012-01-01 00:01:00 -0.889751  \n",
      "2012-01-01 00:02:00 -0.901803  \n",
      "2012-01-01 00:03:00 -0.913855  \n",
      "2012-01-01 00:04:00 -0.925907  \n",
      "2012-01-01 00:05:00 -0.937959  \n",
      "2012-01-01 00:06:00 -0.951760  \n",
      "2012-01-01 00:07:00 -0.965560  \n",
      "2012-01-01 00:08:00 -0.979361  \n",
      "2012-01-01 00:09:00 -0.993161  \n"
     ]
    }
   ],
   "source": [
    "df_upsampled = upsample_dataframe(df_downsampled, 'upsampled_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f2cf8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_entire_sequence(\n",
    "    data: pd.DataFrame, \n",
    "    window_size: int, \n",
    "    step_size: int\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        Produce all the start and end index positions that is needed to produce\n",
    "        the sub-sequences. \n",
    "        Returns a list of tuples. Each tuple is (start_idx, end_idx) of a sub-\n",
    "        sequence. These tuples should be used to slice the dataset into sub-\n",
    "        sequences. These sub-sequences should then be passed into a function\n",
    "        that slices them into input and target sequences. \n",
    "        \n",
    "        Args:\n",
    "            data (pd.DataFrame): Partitioned data set, e.g. training data\n",
    "            \n",
    "            window_size (int): The desired length of each sub-sequence. Should be\n",
    "                               (input_sequence_length + target_sequence_length)\n",
    "                               E.g. if you want the model to consider the past 100\n",
    "                               time steps in order to predict the future 50 \n",
    "                               time steps, window_size = 100+50 = 150\n",
    "            step_size (int): Size of each step as the data sequence is traversed \n",
    "                             by the moving window.\n",
    "                             If 1, the first sub-sequence will be [0:window_size], \n",
    "                             and the next will be [1:window_size].\n",
    "        Return:\n",
    "            indices: a list of tuples\n",
    "        \"\"\"\n",
    "\n",
    "        stop_position = len(data)-1 # 1- because of 0 indexing\n",
    "        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        \n",
    "        subseq_last_idx = window_size\n",
    "        \n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "\n",
    "            indices.append((subseq_first_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            \n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "841566c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "\n",
    "def get_xgboost_x_y(\n",
    "    indices: List[Tuple[int, int]], \n",
    "    data: pd.DataFrame,\n",
    "    target_sequence_length: int,\n",
    "    input_seq_len: int,\n",
    "    target_col: str = \"Series1\"\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        indices: List of (start_idx, end_idx) positions at which data should be sliced\n",
    "        data: Multivariate time series DataFrame with datetime index (columns = Series1, Series2, ...)\n",
    "        target_sequence_length: The forecasting horizon (m)\n",
    "        input_seq_len: The input window size (n)\n",
    "\n",
    "    Returns:\n",
    "        all_x: np.ndarray of shape (number of instances, input_seq_len * number_of_features)\n",
    "        all_y: np.ndarray of shape (number of instances, target_sequence_length)\n",
    "    \"\"\"\n",
    "\n",
    "    num_features = data.shape[1]  # Number of columns/series\n",
    "    all_x, all_y = None, None\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        data_instance = data.iloc[idx[0]:idx[1]].values  # (window_size, num_features)\n",
    "\n",
    "        x = data_instance[0:input_seq_len, :]  # (input_seq_len, num_features)\n",
    "        y = data[target_col].iloc[idx[0] + input_seq_len : idx[0] + input_seq_len + target_sequence_length].values\n",
    "        \n",
    "        assert x.shape == (input_seq_len, num_features), f\"x shape {x.shape} != ({input_seq_len}, {num_features})\"\n",
    "        assert len(y) == target_sequence_length, f\"y length {len(y)} != {target_sequence_length}\"\n",
    "\n",
    "        x_flat = x.flatten()  # Flatten into (input_seq_len * num_features,)\n",
    "        \n",
    "        if i == 0:\n",
    "            all_x = x_flat.reshape(1, -1)\n",
    "            all_y = y.reshape(1, -1)\n",
    "        else:\n",
    "            all_x = np.concatenate((all_x, x_flat.reshape(1, -1)), axis=0)\n",
    "            all_y = np.concatenate((all_y, y.reshape(1, -1)), axis=0)\n",
    "\n",
    "\n",
    "    return all_x, all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "131f4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_XY_train_XY_test(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    hyperparameters: dict, \n",
    "    target_sequence_length: int,\n",
    "    series: str\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate training and test data for XGBoost model.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Downsampled DataFrame with datetime index.\n",
    "        hyperparameters (dict): Hyperparameters for the model.\n",
    "        target_sequence_length (int): Length of the target sequence.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: x_train, y_train, x_test, y_test\n",
    "    \"\"\"\n",
    "\n",
    "    training_indices = get_indices_entire_sequence(\n",
    "        data=train_df, \n",
    "        window_size=hyperparameters[\"in_length\"]+target_sequence_length, \n",
    "        step_size=hyperparameters[\"step_size\"]\n",
    "        )\n",
    "\n",
    "    x_train, y_train = get_xgboost_x_y(\n",
    "        indices=training_indices, \n",
    "        data=train_df[hyperparameters[\"selected_features\"]],\n",
    "        target_sequence_length=target_sequence_length,\n",
    "        input_seq_len=hyperparameters[\"in_length\"],\n",
    "        target_col=series\n",
    "        )\n",
    "\n",
    "    test_indices = get_indices_entire_sequence(\n",
    "        data=test_df, \n",
    "        window_size=hyperparameters[\"in_length\"]+target_sequence_length, \n",
    "        step_size=target_sequence_length\n",
    "        )\n",
    "\n",
    "    x_test, y_test = get_xgboost_x_y(\n",
    "        indices=test_indices, \n",
    "        data=test_df[hyperparameters[\"selected_features\"]],\n",
    "        target_sequence_length=target_sequence_length,\n",
    "        input_seq_len=hyperparameters[\"in_length\"],\n",
    "        target_col=series\n",
    "        )\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a1f567bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "def train_xgboost_model(\n",
    "    x_train: np.ndarray, \n",
    "    y_train: np.ndarray, \n",
    "    hyperparameters: dict\n",
    "    ) -> MultiOutputRegressor:\n",
    "    \"\"\"\n",
    "    Train an XGBoost model for multi-output regression.\n",
    "\n",
    "    Args:\n",
    "        x_train (np.ndarray): Training input data.\n",
    "        y_train (np.ndarray): Training target data.\n",
    "        hyperparameters (dict): Hyperparameters for the model.\n",
    "\n",
    "    Returns:\n",
    "        MultiOutputRegressor: Trained XGBoost model.\n",
    "    \"\"\"\n",
    "    model = xgb.XGBRegressor(\n",
    "    n_estimators=hyperparameters[\"n_estimators\"],\n",
    "    max_depth=hyperparameters[\"max_depth\"],\n",
    "    subsample=hyperparameters[\"subsample\"],\n",
    "    min_child_weight=hyperparameters[\"min_child_weight\"],\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\"\n",
    "    )\n",
    "    \n",
    "    trained_model = MultiOutputRegressor(model).fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1495f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def model_predict(\n",
    "    model: MultiOutputRegressor, \n",
    "    x_test: np.ndarray, \n",
    "    y_test: np.ndarray,\n",
    "    test_data: pd.DataFrame,\n",
    "    ) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the test data.\n",
    "\n",
    "    Args:\n",
    "        model (MultiOutputRegressor): Trained XGBoost model.\n",
    "        x_test (np.ndarray): Test input data.\n",
    "        y_test (np.ndarray): Test target data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]: RMSE, MAE, and R2 score of the model on the test data.\n",
    "    \"\"\"\n",
    "    test_forecasts = model.predict(x_test)\n",
    "    test_forecasts = test_forecasts.flatten()\n",
    "\n",
    "    if len(test_forecasts) <= len(test_data):\n",
    "        test_data = test_data.iloc[:len(test_forecasts)]\n",
    "    else:\n",
    "        raise ValueError(\"Test forecasts and test data lengths do not match.\")\n",
    "        \n",
    "    forecast_df = pd.DataFrame(\n",
    "        {\"Forecast\": test_forecasts}, \n",
    "        index=test_data.index\n",
    "    )\n",
    "\n",
    "    forecast_df = upsample_dataframe(forecast_df, 'forecast_upsampled.csv')\n",
    "\n",
    "    if len(forecast_df) < len(y_test):\n",
    "        y_test = y_test[:len(forecast_df)]\n",
    "    else:\n",
    "        raise ValueError(\"Forecast and test data lengths do not match.\")\n",
    "    \n",
    "    return forecast_df, y_test\n",
    "\n",
    "def evaluate_model(\n",
    "    forecast_df: pd.DataFrame,\n",
    "    y_test: np.ndarray,\n",
    "    ) -> Tuple[float, float, float]:\n",
    "    test_mae = mean_absolute_error(y_test, forecast_df)\n",
    "    test_mse = mean_squared_error(y_test, forecast_df)\n",
    "    test_r2 = r2_score(y_test, forecast_df)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    \n",
    "    return test_rmse, test_mae, test_r2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e45804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_model(forecast_df: pd.DataFrame, y_test: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Visualize the model's forecasts against the actual test data.\n",
    "\n",
    "    Args:\n",
    "        forecast_df (pd.DataFrame): DataFrame containing the model's forecasts.\n",
    "        y_test (np.ndarray): Actual test data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    start_idx = 4900\n",
    "    end_idx = start_idx + 10000\n",
    "\n",
    "    fontsize = 16\n",
    "    plot_df = pd.DataFrame({\n",
    "        \"Forecasts\": forecast_df[\"Forecast\"].values[start_idx:end_idx],\n",
    "        \"Targets\": y_test[start_idx:end_idx]\n",
    "    }, index=forecast_df.index[start_idx:end_idx])\n",
    "\n",
    "    fig = plt.figure(figsize=(20,12))\n",
    "    plt.plot(plot_df.index, plot_df[\"Forecasts\"], label=\"Forecasts\")\n",
    "    plt.plot(plot_df.index, plot_df[\"Targets\"], label=\"Targets\")\n",
    "\n",
    "    plt.xlabel('Time', fontsize=fontsize)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.ylabel(\"Electricity price, EUR/MWh\", fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "eae4b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_xgboost_model(\n",
    "    df: pd.DataFrame, series: str, visualize: bool = False\n",
    ") -> MultiOutputRegressor:\n",
    "\n",
    "    df_downsampled = downsample_df(df, n_minutes=5)\n",
    "\n",
    "    target_variables = [\n",
    "        \"Series1\",\n",
    "        \"Series2\",\n",
    "        \"Series3\",\n",
    "        \"Series4\",\n",
    "        \"Series5\",\n",
    "        \"Series6\",\n",
    "    ]\n",
    "    hyperparameters = {\n",
    "        \"in_length\": [15],\n",
    "        \"step_size\": [15],\n",
    "        \"n_estimators\": [10, 20, 50],\n",
    "        \"max_depth\": [4, 6, 8],\n",
    "        \"subsample\": [0.5, 0.7, 1.0],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"min_child_weight\": [1, 2, 3],\n",
    "        \"selected_features\": [target_variables],\n",
    "    }\n",
    "    \n",
    "    target_sequence_length = 60 * 4 // 5\n",
    "    first_day_test = \"2013-07-01\"\n",
    "\n",
    "    training_data = df_downsampled[df_downsampled.index < first_day_test]\n",
    "\n",
    "    test_data = df_downsampled[df_downsampled.index >= first_day_test]\n",
    "    \n",
    "    param_combinations = list(itertools.product(\n",
    "        hyperparameters[\"in_length\"],\n",
    "        hyperparameters[\"step_size\"],\n",
    "        hyperparameters[\"n_estimators\"],\n",
    "        hyperparameters[\"max_depth\"],\n",
    "        hyperparameters[\"subsample\"],\n",
    "        hyperparameters[\"learning_rate\"],\n",
    "        hyperparameters[\"min_child_weight\"],\n",
    "        hyperparameters[\"selected_features\"]\n",
    "    ))\n",
    "    \n",
    "    param_combinations_df = pd.DataFrame(param_combinations, columns=hyperparameters.keys())\n",
    "    best_model = None\n",
    "    best_r2 = 0  # Initialize to a very high value\n",
    "    for _, params_row in tqdm(param_combinations_df.iterrows(), total=param_combinations_df.shape[0], desc=\"Training Models\"):\n",
    "        params = params_row.to_dict()\n",
    "        X_train, y_train, x_test, y_test = generate_XY_train_XY_test(\n",
    "            train_df=training_data,\n",
    "            test_df=test_data,\n",
    "            hyperparameters=params,\n",
    "            target_sequence_length=target_sequence_length,\n",
    "            series=series,\n",
    "        )\n",
    "\n",
    "        model = train_xgboost_model(\n",
    "            x_train=X_train,\n",
    "            y_train=y_train,\n",
    "            hyperparameters=params,\n",
    "        )\n",
    "\n",
    "        forecast_df, y_test = model_predict(\n",
    "            model=model,\n",
    "            x_test=x_test,\n",
    "            y_test=df[series][df.index >= first_day_test].to_numpy(),\n",
    "            test_data=test_data,\n",
    "        )\n",
    "\n",
    "        _, _, r2 = evaluate_model(\n",
    "            forecast_df=forecast_df,\n",
    "            y_test=y_test,\n",
    "        )\n",
    "        \n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_model = model  # Save the current best model\n",
    "            print(f\"New best model found with R2: {best_r2} - Hyperparameters: {params}\")\n",
    "\n",
    "    # if visualize:\n",
    "        # visualize_model(forecast_df, y_test)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "767ee6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   0%|▏                                                       | 1/243 [00:12<52:12, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with R2: 0.7606234471672974 - Hyperparameters: {'in_length': 15, 'step_size': 15, 'n_estimators': 10, 'max_depth': 4, 'subsample': 0.5, 'learning_rate': 0.01, 'min_child_weight': 1, 'selected_features': ['Series1', 'Series2', 'Series3', 'Series4', 'Series5', 'Series6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   1%|▋                                                       | 3/243 [00:35<46:50, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with R2: 0.7610364083789404 - Hyperparameters: {'in_length': 15, 'step_size': 15, 'n_estimators': 10, 'max_depth': 4, 'subsample': 0.5, 'learning_rate': 0.01, 'min_child_weight': 3, 'selected_features': ['Series1', 'Series2', 'Series3', 'Series4', 'Series5', 'Series6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   8%|████▎                                                  | 19/243 [03:42<41:38, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with R2: 0.7615144272951921 - Hyperparameters: {'in_length': 15, 'step_size': 15, 'n_estimators': 10, 'max_depth': 4, 'subsample': 1.0, 'learning_rate': 0.01, 'min_child_weight': 1, 'selected_features': ['Series1', 'Series2', 'Series3', 'Series4', 'Series5', 'Series6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   8%|████▌                                                  | 20/243 [03:53<40:57, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with R2: 0.761661684043279 - Hyperparameters: {'in_length': 15, 'step_size': 15, 'n_estimators': 10, 'max_depth': 4, 'subsample': 1.0, 'learning_rate': 0.01, 'min_child_weight': 2, 'selected_features': ['Series1', 'Series2', 'Series3', 'Series4', 'Series5', 'Series6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:   9%|████▊                                                  | 21/243 [04:03<40:33, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with R2: 0.7619878572302599 - Hyperparameters: {'in_length': 15, 'step_size': 15, 'n_estimators': 10, 'max_depth': 4, 'subsample': 1.0, 'learning_rate': 0.01, 'min_child_weight': 3, 'selected_features': ['Series1', 'Series2', 'Series3', 'Series4', 'Series5', 'Series6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  41%|██████████████████████▏                               | 100/243 [26:59<30:19, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with R2: 0.7631448140611754 - Hyperparameters: {'in_length': 15, 'step_size': 15, 'n_estimators': 20, 'max_depth': 4, 'subsample': 1.0, 'learning_rate': 0.01, 'min_child_weight': 1, 'selected_features': ['Series1', 'Series2', 'Series3', 'Series4', 'Series5', 'Series6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models:  42%|██████████████████████▋                               | 102/243 [27:25<30:10, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found with R2: 0.7631701469804526 - Hyperparameters: {'in_length': 15, 'step_size': 15, 'n_estimators': 20, 'max_depth': 4, 'subsample': 1.0, 'learning_rate': 0.01, 'min_child_weight': 3, 'selected_features': ['Series1', 'Series2', 'Series3', 'Series4', 'Series5', 'Series6']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Models: 100%|████████████████████████████████████████████████████| 243/243 [1:55:19<00:00, 28.47s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_clean.csv', parse_dates=['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "best_model = generate_xgboost_model(df, \"Series1\", visualize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
