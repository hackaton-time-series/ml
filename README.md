# Проєкт: Прогнозування Корельованих Часових Рядів

## Завдання

Розробити та навчити модель для прогнозування значення 6 сильно корельованих часових рядів на **4 години (240 хвилин)** вперед. Прогноз має генеруватися **щохвилини** для кожного ряду, використовуючи лише поточні або минулі дані.

## 1. EDA (Дослідження даних)

Проведено комплексний аналіз вихідних даних (`data.csv`, ~22 місяці):

* **Пропущені значення:** Виявлено приблизно **~5%** пропущених значень у кожному ряді. Аналіз за допомогою `missingno` (матриця, теплова карта) показав, що пропуски є **розсіяними** (немає великих безперервних блоків) і **некорельованими** між рядами (пропуск в одному ряді не означає пропуск в іншому в той же час).
* **Викиди:** Дані містять викиди. Було застосовано метод **IQR (міжквартильний розмах) з множником 1.5** для їх ідентифікації та заміни на NaN перед фінальною інтерполяцією. Також тестувався підхід без видалення викидів, але з огляду на використання MAE-втрат (`regression_l1`) в LightGBM, що є стійким до викидів, та схожі результати, було вирішено залишити їх обробку методом IQR як стандартний крок очищення.
* **Стаціонарність:** Початкові тести (ADF) вказували на **нестаціонарність** рядів на рівнях, що є типовим для фінансових даних.
* **Сезонність:** Аналіз середніх значень за годинами та днями тижня виявив **сильні добові та особливо тижневі сезонні патерни** (значення на вихідних помітно відрізняються від будніх днів).
* **Крос-кореляція:**
    * Стандартна кореляційна матриця підтвердила наявність **помірної одночасної кореляції** між рядами.
    * Аналіз функції крос-кореляції (CCF) показав, що **найсильніша кореляція спостерігається при нульовому лазі (Lag 0)**. Виявлено лише **дуже слабкі та короткі (2-6 хвилин) взаємозв'язки випередження/запізнення** між деякими парами рядів, які навряд чи будуть інформативними для 4-годинного прогнозу.
* **Аналіз помилок моделі (з попередніх ітерацій):**
    * Помилки прогнозування (залишки) демонстрували **сильну автокореляцію** (високі значення ACF на багатьох лагах), що вказувало на невикористану тимчасову структуру даних.
    * Спостерігалася **гетероскедастичність** (зміна дисперсії помилок у часі), причому більші помилки часто збігалися з періодами вищої волатильності вихідних даних.
    * Розподіл помилок був близьким до нуля в середньому (низький біас), але мав "товсті хвости".

## 2. Створення фіч (Feature Engineering)

На основі EDA та ітераційних експериментів, фінальний набір фічей для моделі LightGBM включає:

* **Календарні фічі:**
    * Базові: `hour`, `day_of_week`, `day_of_year`, `month`, `week_of_year`, `year`, `is_weekend`.
    * Тригонометричні (для кращого представлення циклічності для дерев): `hour_sin`, `hour_cos`, `dow_sin`, `dow_cos`, `month_sin`, `month_cos`.
* **Лагові фічі самої серії (Self-Lags):** Значення ряду в минулому (`lag_1`, `lag_5`, `lag_15`, `lag_60`, `lag_240`, `lag_255`). Лаг `lag_240` виявився надзвичайно важливим.
* **Ковзні статистики самої серії (Self-Rolling Stats):** Середнє та стандартне відхилення за вікнами 15, 60 та 240 хвилин (`rollmean_W`, `rollstd_W`), розраховані з `closed='left'` для уникнення витоку даних.
* **Прості крос-лагові фічі (Simple Cross-Lags):** Значення *інших* рядів з невеликими затримками (`SeriesX_X_SeriesY_lag_1`, `SeriesX_X_SeriesY_lag_5`).

**Відкинуті фічі:** Під час експериментів були протестовані, але **виключені** з фінального набору через низьку важливість (за feature importance) та відсутність покращення метрик на тестовому наборі:
* Складні крос-серійні фічі (ковзні середні/стандартні відхилення інших рядів, різниці між парами рядів, крос-волатильність).

## 3. Обробка пропусків (Handling Missing Values)

* Початкові ~5% пропущених значень обробляються за допомогою **часової лінійної інтерполяції** (`interpolate(method='time')`). Цей метод обрано через відносно невеликий відсоток пропусків та їх розсіяний, некорельований характер (згідно з EDA).
* Додаткові NaN, що виникають після видалення викидів методом IQR, також заповнюються за допомогою `interpolate(method='time')`.
* Фінальна перевірка та інтерполяція після встановлення частоти (`asfreq`) гарантують відсутність пропусків перед створенням фіч.

## 4. Обробка кореляцій між рядами (Handling Cross-Series Correlations)

* Завдання вимагало врахування кореляції між рядами.
* EDA (CCF) показало, що основна кореляція є одночасною (Lag 0), а зв'язки випередження/запізнення слабкі та короткострокові.
* У фінальну модель включено **прості крос-лагові фічі** (`lag_1`, `lag_5` інших рядів), щоб спробувати врахувати короткострокові взаємозв'язки.
* Спроби додати більш складні крос-серійні фічі (ковзні статистики інших рядів, різниці між парами) не призвели до покращення результатів і були відкинуті. Модель стабільно надавала перевагу власній історії ряду.

## 5. Використані ML/DL моделі (ML/DL Models Used)

* Основною моделлю, використаною для фінальних результатів, є **LightGBM** (реалізація градієнтного бустингу).
* Обрано стратегію навчання **6 незалежних моделей LightGBM**, по одній для прогнозування кожного з 6 цільових часових рядів. Це дозволяє кожній моделі спеціалізуватися на своєму ряді, використовуючи при цьому повний набір фічей (включаючи інформацію з інших рядів).
* Як цільову змінну використовується **абсолютне значення** ряду через 4 години (`value[t+240]`).
    * *Експеримент:* Тестувалося прогнозування різниці (`value[t+240] - value[t]`) та першої різниці (`value[t] - value[t-1]`), але це не покращило (або навіть погіршило) фінальні метрики на абсолютних значеннях після реконструкції.
* *Потенційний наступний крок:* З огляду на автокореляцію помилок, наступним кроком для потенційного покращення могла б бути спроба моделей, що краще працюють з послідовностями, наприклад, **LSTM**.

## 6. Процес навчання моделей (Model Training Process)

1.  **Підготовка даних:** Завантаження, очищення (інтерполяція NaN, видалення викидів IQR), генерація фічей (календарні+триг, лаги, ковзні статистики) на повному історичному наборі даних.
2.  **Розбиття Train/Test:** Навчальний набір (`train_df`) містить усі дані *до* дати початку наданого тестового файлу (`Timeseries_six_test.csv`). Тестовий набір фічей (`X_test`) містить фічі, що відповідають часовим міткам з `Timeseries_six_test.csv`.
3.  **Оптимізація гіперпараметрів:**
    * Використовується бібліотека **Optuna** для автоматичного пошуку оптимальних гіперпараметрів LightGBM.
    * Застосовується **TimeSeriesSplit** з параметром `gap=FORECAST_HORIZON` (240 хвилин) для крос-валідації на навчальному наборі. Це забезпечує більш надійну оцінку узагальнюючої здатності моделі та запобігає витоку даних під час валідації.
    * Як цільова функція для Optuna використовується MAE (`objective='regression_l1'`), метрика для оцінки - RMSE.
4.  **Визначення Оптимальної К-сті Ітерацій:** Після знаходження найкращих параметрів Optuna, проводиться тренування з ранньою зупинкою (early stopping) на внутрішній валідаційній вибірці (останні 10% тренувальних даних), щоб визначити оптимальну кількість бустингових раундів (дерев).
5.  **Фінальне Тренування:** Навчаються 6 окремих моделей LightGBM на **всьому** тренувальному наборі (`X_train`, `y_train`), використовуючи найкращі параметри з Optuna та оптимальну кількість раундів, знайдену на попередньому кроці.

## 7. Перевірка на Look-ahead Bias

Вжито заходів для запобігання витоку майбутньої інформації в минуле (Look-ahead Bias):

* **Розбиття даних:** Чітке хронологічне розбиття на тренувальний набір (дані до початку тестового періоду) та тестовий набір (дані з тестового періоду).
* **Генерація фіч:** Усі лагові фічі використовують `shift(n)` з `n >= 1`. Усі ковзні статистики використовують `closed='left'`, що гарантує використання лише минулих даних для розрахунку вікна.
* **Крос-валідація:** Використання `TimeSeriesSplit` гарантує, що на кожному фолді валідація відбувається на даних, які йдуть *після* тренувальних даних цього фолду. Додатково використовується `gap=FORECAST_HORIZON`, щоб створити буфер між тренувальним та валідаційним наборами, роблячи оцінку ще більш надійною щодо майбутньої продуктивності.

Ці заходи гарантують, що модель навчається та валідується лише на основі інформації, яка була б доступна на момент прогнозування.
