{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c861696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "    \n",
    "def val_step(\n",
    "    logits: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    criterion: torch.nn.MSELoss\n",
    ") -> torch.Tensor:\n",
    "    loss = criterion(logits, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_step(\n",
    "    model,\n",
    "    logits: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    criterion: torch.nn.MSELoss,\n",
    "    optimizer: torch.optim.Optimizer\n",
    ") -> torch.Tensor:\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(logits, labels)\n",
    "    loss.backward()\n",
    "    max_norm = 1.0 # Define the maximum allowed gradient norm\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    timestamps: int = 36,\n",
    "    epochs: int = 20,\n",
    "    device: str = \"cuda\"\n",
    ") -> None:\n",
    "    \n",
    "    criterion = nn.HuberLoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        losses = []\n",
    "        r2s = []\n",
    "        mses = []\n",
    "        rmses = []\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        train_tqdm = tqdm(train_dataloader, total=len(train_dataloader))\n",
    "        \n",
    "        for inputs, labels in train_tqdm:\n",
    "            \n",
    "            inputs = inputs.to(\"cuda\")\n",
    "            labels = labels.to(\"cuda\")\n",
    "            \n",
    "            logits: torch.Tensor = model(inputs).squeeze(1)\n",
    "            \n",
    "            loss = train_step(model, logits, labels, criterion, optimizer)\n",
    "            \n",
    "            r2 = r2_score(logits.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            mse = mean_absolute_error(logits.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            rmse = root_mean_squared_error(logits.detach().cpu().numpy(), labels.detach().cpu().numpy())\n",
    "            \n",
    "            r2s.append(r2)\n",
    "            mses.append(mse)\n",
    "            rmses.append(rmse)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            train_tqdm.set_description(\n",
    "                f\"Train Epoch {epoch}, Loss - {np.mean(losses):0.4f}, R^2 - {np.mean(r2s):0.4f}, MAE - {np.mean(mses):0.4f}, RMSE - {np.mean(rmses):0.4f}\"\n",
    "            )\n",
    "            \n",
    "        r2s.clear()\n",
    "        mses.clear()\n",
    "        rmses.clear()\n",
    "        losses.clear()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            test_tqdm = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "            \n",
    "            for full_batch in test_tqdm:\n",
    "                \n",
    "                full_batch = full_batch.to(device)\n",
    "                \n",
    "                inputs = full_batch[:, :-timestamps, :]\n",
    "                labels = full_batch[:, -timestamps:, :][::240]\n",
    "                \n",
    "                logits = model(inputs)\n",
    "            \n",
    "                eval_labels = labels.reshape(test_dataloader.batch_size, -1)\n",
    "                eval_logits = logits.reshape(test_dataloader.batch_size, -1)\n",
    "\n",
    "                loss = val_step(eval_logits, eval_labels, criterion)\n",
    "            \n",
    "                r2 = r2_score(eval_logits.detach().cpu().numpy(), eval_labels.detach().cpu().numpy())\n",
    "                mse = mean_absolute_error(eval_logits.detach().cpu().numpy(), eval_labels.detach().cpu().numpy())\n",
    "                rmse = root_mean_squared_error(eval_logits.detach().cpu().numpy(), eval_labels.detach().cpu().numpy())\n",
    "                \n",
    "                r2s.append(r2)\n",
    "                mses.append(mse)\n",
    "                rmses.append(rmse)\n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                test_tqdm.set_description(\n",
    "                    f\"Test, Loss - {np.mean(losses):0.4f}, R^2 - {np.mean(r2s):0.4f}, MAE - {np.mean(mses):0.4f}, RMSE - {np.mean(rmses):0.4f}\"\n",
    "                )\n",
    "                \n",
    "        print()\n",
    "\n",
    "    torch.save(model.state_dict(), \"lstm_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c5f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.1466, R^2 - -82031.6428, MAE - 0.2700, RMSE - 0.3014:   0%|          | 60/58031 [00:00<03:11, 303.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0748, R^2 - -70247.4817, MAE - 0.1758, RMSE - 0.2068:   0%|          | 132/58031 [00:00<02:51, 336.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0521, R^2 - -55766.1368, MAE - 0.1457, RMSE - 0.1767:   0%|          | 204/58031 [00:00<02:46, 347.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0415, R^2 - -42956.8364, MAE - 0.1308, RMSE - 0.1635:   0%|          | 277/58031 [00:00<02:44, 352.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0348, R^2 - -34698.3804, MAE - 0.1194, RMSE - 0.1527:   1%|          | 348/58031 [00:01<02:46, 346.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0302, R^2 - -29246.0025, MAE - 0.1109, RMSE - 0.1449:   1%|          | 418/58031 [00:01<02:46, 345.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0269, R^2 - -25401.1937, MAE - 0.1043, RMSE - 0.1393:   1%|          | 454/58031 [00:01<02:46, 346.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0244, R^2 - -22500.0992, MAE - 0.0989, RMSE - 0.1348:   1%|          | 527/58031 [00:01<02:43, 352.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0225, R^2 - -20202.4272, MAE - 0.0945, RMSE - 0.1307:   1%|          | 600/58031 [00:01<02:41, 354.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0209, R^2 - -18455.6988, MAE - 0.0913, RMSE - 0.1279:   1%|          | 672/58031 [00:02<02:42, 351.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0196, R^2 - -17111.4509, MAE - 0.0884, RMSE - 0.1251:   1%|▏         | 744/58031 [00:02<02:43, 350.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0186, R^2 - -16201.2221, MAE - 0.0861, RMSE - 0.1230:   1%|▏         | 816/58031 [00:02<02:43, 349.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0176, R^2 - -15695.9280, MAE - 0.0841, RMSE - 0.1211:   2%|▏         | 886/58031 [00:02<02:44, 348.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0173, R^2 - -15525.7363, MAE - 0.0833, RMSE - 0.1202:   2%|▏         | 942/58031 [00:02<02:44, 346.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n",
      "logits:  torch.Size([16, 6])\n",
      "labels:  torch.Size([16, 6])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TimestampsDataset(data\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), lags\u001b[38;5;241m=\u001b[39mINPUT_SEQUENCE \u001b[38;5;241m+\u001b[39m OUTPUT_SEQUENCE)\n\u001b[1;32m     11\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TimestampsDataset(data\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), lags\u001b[38;5;241m=\u001b[39mINPUT_SEQUENCE \u001b[38;5;241m+\u001b[39m OUTPUT_SEQUENCE)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_SEQUENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 57\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, timestamps, epochs, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     55\u001b[0m train_tqdm \u001b[38;5;241m=\u001b[39m tqdm(train_dataloader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader))\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_tqdm:\n\u001b[1;32m     59\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:729\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/autograd/profiler.py:788\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m--> 788\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_exit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/_ops.py:995\u001b[0m, in \u001b[0;36mTorchBindOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_as_effectful_op_temporarily():\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_in_python(args, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fallthrough_keys())\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.dataset import TimestampsDataset\n",
    "from src.lstm import LSTMForecaster\n",
    "\n",
    "INPUT_SEQUENCE = 239\n",
    "OUTPUT_SEQUENCE = 1\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "model = LSTMForecaster(input_features=6, output_timestamps=OUTPUT_SEQUENCE, hidden_size=64, num_layers=2)\n",
    "model = model.to(DEVICE)\n",
    "train_dataset = TimestampsDataset(data=Path(\"train.csv\"), lags=INPUT_SEQUENCE + OUTPUT_SEQUENCE)\n",
    "test_dataset = TimestampsDataset(data=Path(\"test.csv\"), lags=INPUT_SEQUENCE + OUTPUT_SEQUENCE)\n",
    "\n",
    "train(\n",
    "    timestamps=OUTPUT_SEQUENCE,\n",
    "    model=model, \n",
    "    train_dataloader=torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    ),\n",
    "    test_dataloader=torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    ),\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca0a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Injects positional information into the input embeddings.\n",
    "    Uses sine and cosine functions of different frequencies.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Create a long enough positional encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # Shape: [max_len, 1]\n",
    "        # Term for calculating frequencies\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        # Apply sine to even indices in pe\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # Apply cosine to odd indices in pe\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # Add a batch dimension: [1, max_len, d_model] -> becomes [max_len, 1, d_model] after unsqueeze(0) below\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1) # Shape: [max_len, 1, d_model]\n",
    "\n",
    "        # Register 'pe' as a buffer that should not be considered a model parameter.\n",
    "        # 'pe' will be moved to the correct device along with the module.\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [sequence_length, batch_size, d_model]\n",
    "               OR [batch_size, sequence_length, d_model] if batch_first=True elsewhere\n",
    "        \"\"\"\n",
    "        # If batch_first=True was used for the input x to this module:\n",
    "        # x shape: [batch_size, sequence_length, d_model]\n",
    "        # self.pe shape: [max_len, 1, d_model]\n",
    "        # We need to add positional encodings to x.\n",
    "        # Select positional encodings up to the sequence length of x: self.pe[:x.size(1), :]\n",
    "        # Transpose pe slice to match x's batch-first format if needed, or adjust x.\n",
    "        # Let's assume x comes in as [batch_size, sequence_length, d_model]\n",
    "        # self.pe[:x.size(1), :].transpose(0,1) gives shape [1, sequence_length, d_model]\n",
    "        # This will broadcast correctly during addition.\n",
    "\n",
    "        # If x is [sequence_length, batch_size, d_model] (PyTorch default)\n",
    "        # x = x + self.pe[:x.size(0), :]\n",
    "        # return self.dropout(x)\n",
    "\n",
    "        # If x is [batch_size, sequence_length, d_model] (using batch_first=True)\n",
    "        # Need pe slice shape [1, sequence_length, d_model]\n",
    "        pe_slice = self.pe[:x.size(1), :].transpose(0, 1) # Shape [1, sequence_length, d_model]\n",
    "        x = x + pe_slice # Broadcasting adds positional encoding to each batch element\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerTimeSeriesPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based model for time series prediction.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): The number of features in the input time series (e.g., 6).\n",
    "        d_model (int): The dimension of the transformer embeddings and hidden layers.\n",
    "                       Must be divisible by nhead.\n",
    "        nhead (int): The number of attention heads in the multi-head attention mechanism.\n",
    "        num_encoder_layers (int): The number of stacked transformer encoder layers.\n",
    "        dim_feedforward (int): The dimension of the feedforward network model in encoder layers.\n",
    "        output_dim (int): The number of time steps to predict into the future.\n",
    "        dropout (float): Dropout probability.\n",
    "        max_len (int): Maximum sequence length for positional encoding.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, output_dim, dropout=0.1, max_len=5000):\n",
    "        super(TransformerTimeSeriesPredictor, self).__init__()\n",
    "        \n",
    "        self.output_timestamps = output_dim\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # --- Input Embedding ---\n",
    "        # Linear layer to project input features to d_model dimension\n",
    "        self.input_embedding = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # --- Positional Encoding ---\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len)\n",
    "\n",
    "        # --- Transformer Encoder ---\n",
    "        # Define a single encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation='relu', # or 'gelu'\n",
    "            batch_first=True # IMPORTANT: Input/Output shape (batch, seq, feature)\n",
    "        )\n",
    "        # Stack multiple encoder layers\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=num_encoder_layers,\n",
    "            norm=nn.LayerNorm(d_model) # Optional final normalization\n",
    "        )\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        # Linear layer to map the final transformer output to the desired prediction dimension\n",
    "        self.output_layer = nn.Linear(d_model, output_dim)\n",
    "\n",
    "        # Initialize weights (optional but often recommended)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # Initialize weights for linear layers\n",
    "        initrange = 0.1\n",
    "        self.input_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.input_embedding.bias.data.zero_()\n",
    "        self.output_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        self.output_layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            src (torch.Tensor): The input time series data with shape\n",
    "                               (batch_size, sequence_length, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The predicted values with shape (batch_size, output_dim).\n",
    "        \"\"\"\n",
    "        # 1. Input Embedding\n",
    "        # src shape: [batch_size, seq_len, input_dim]\n",
    "        # embedded shape: [batch_size, seq_len, d_model]\n",
    "        embedded = self.input_embedding(src) * math.sqrt(self.d_model) # Scale embedding\n",
    "\n",
    "        # 2. Positional Encoding\n",
    "        # pos_encoded shape: [batch_size, seq_len, d_model]\n",
    "        pos_encoded = self.pos_encoder(embedded)\n",
    "\n",
    "        # 3. Transformer Encoder\n",
    "        # encoder_output shape: [batch_size, seq_len, d_model]\n",
    "        # Note: No mask is applied here, assuming we only use the final output\n",
    "        # for forecasting. If using for other tasks or intermediate outputs,\n",
    "        # a mask might be needed (e.g., nn.Transformer.generate_square_subsequent_mask).\n",
    "        encoder_output = self.transformer_encoder(pos_encoded)\n",
    "\n",
    "        # 4. Output Layer\n",
    "        # We typically use the output corresponding to the *last* time step\n",
    "        # of the input sequence for forecasting.\n",
    "        # last_step_output shape: [batch_size, d_model]\n",
    "        last_step_output = encoder_output[:, -1, :]\n",
    "\n",
    "        # prediction shape: [batch_size, output_dim]\n",
    "        prediction = self.output_layer(last_step_output)\n",
    "\n",
    "        return prediction.reshape(src.shape[0], self.output_timestamps // 6, self.input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5599d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 0, Loss - 0.0226, R^2 - -29.8695, MAE - 0.0822, RMSE - 0.1218: 100%|██████████| 58039/58039 [06:22<00:00, 151.61it/s]\n",
      "  0%|          | 0/563 [00:00<?, ?it/s]/home/kostiuk/challanges/ml/env/lib/python3.10/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([16, 90])) that is different to the input size (torch.Size([16, 1440])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  0%|          | 0/563 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1440) must match the size of tensor b (90) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TimestampsDataset(data\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), lags\u001b[38;5;241m=\u001b[39mINPUT_SEQUENCE \u001b[38;5;241m+\u001b[39m OUTPUT_SEQUENCE)\n\u001b[1;32m     31\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TimestampsDataset(data\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), lags\u001b[38;5;241m=\u001b[39mINPUT_SEQUENCE \u001b[38;5;241m+\u001b[39m OUTPUT_SEQUENCE)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_SEQUENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     50\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 107\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, timestamps, epochs, device)\u001b[0m\n\u001b[1;32m    104\u001b[0m eval_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mreshape(test_dataloader\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    105\u001b[0m eval_logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mreshape(test_dataloader\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(eval_logits\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), eval_labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    110\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_absolute_error(eval_logits\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), eval_labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m, in \u001b[0;36mval_step\u001b[0;34m(logits, labels, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mval_step\u001b[39m(\n\u001b[1;32m     10\u001b[0m     logits: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m     11\u001b[0m     labels: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m     12\u001b[0m     criterion: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss\n\u001b[1;32m     13\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/nn/modules/loss.py:610\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/nn/functional.py:3884\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3882\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3884\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n",
      "File \u001b[0;32m~/challanges/ml/env/lib/python3.10/site-packages/torch/functional.py:77\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1440) must match the size of tensor b (90) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from src.dataset import TimestampsDataset\n",
    "\n",
    "INPUT_SEQUENCE = 120\n",
    "OUTPUT_SEQUENCE = 240\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "INPUT_DIM = 6        # Number of features per time step\n",
    "\n",
    "# --- Model Specific Hyperparameters ---\n",
    "D_MODEL = 256        # Embedding dimension (must be divisible by NHEAD)\n",
    "NHEAD = 4            # Number of attention heads\n",
    "NUM_ENCODER_LAYERS = 3 # Number of transformer encoder layers\n",
    "DIM_FEEDFORWARD = 512 # Hidden dimension in feedforward network\n",
    "OUTPUT_DIM = OUTPUT_SEQUENCE * 6      # Predict next 5 time steps\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# --- Model Initialization ---\n",
    "model = TransformerTimeSeriesPredictor(\n",
    "    input_dim=INPUT_DIM,\n",
    "    d_model=D_MODEL,\n",
    "    nhead=NHEAD,\n",
    "    num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "    dim_feedforward=DIM_FEEDFORWARD,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "train_dataset = TimestampsDataset(data=Path(\"train.csv\"), lags=INPUT_SEQUENCE + OUTPUT_SEQUENCE)\n",
    "test_dataset = TimestampsDataset(data=Path(\"test.csv\"), lags=INPUT_SEQUENCE + OUTPUT_SEQUENCE)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    timestamps=OUTPUT_SEQUENCE,\n",
    "    train_dataloader=torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    ),\n",
    "    test_dataloader=torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    ),\n",
    "    device=DEVICE,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71cd071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaff6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
